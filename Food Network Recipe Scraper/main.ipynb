{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.6 64-bit",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "851ca05279024b0f4b3a2b23df08266f641c757c1f9c44a37086823a4283628e"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import scraper_functions as sf\n",
    "import general_functions as gf\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    start_time = time.time()\n",
    "    # todo allow user to select how many recipes they want to look at\n",
    "    search_keyword = 'beef empanadas'\n",
    "    search_url, search_html = get_search_html(search_keyword)\n",
    "    # gf.time_checkpoint('1', start_time)\n",
    "    list_of_page_urls = get_page_urls(search_keyword, search_html)\n",
    "    # gf.time_checkpoint('2', start_time)\n",
    "    list_of_html = get_html_texts(list_of_page_urls)\n",
    "    # gf.time_checkpoint('3', start_time)\n",
    "    recipe_df = extract_recipe_info(list_of_html)\n",
    "    # gf.time_checkpoint('4', start_time)\n",
    "    extract_recipe_ingredients(recipe_df)\n",
    "    # gf.time_checkpoint('5', start_time)\n",
    "    freq_table = analyze_df(recipe_df)\n",
    "    print(freq_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_search_html(search_keyword):\n",
    "    #  get html for search page\n",
    "    search_url = sf.clean_search_url(search_keyword)\n",
    "    search_html = sf.get_html(search_url)\n",
    "\n",
    "    return search_url, search_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_urls(search_keyword, search_html):\n",
    "    # get list of urls using first page html\n",
    "    page_urls = search_html.find_all('li', class_='o-Pagination__a-ListItem')\n",
    "\n",
    "    max_page = 1\n",
    "\n",
    "    for page in page_urls:\n",
    "        clean_page_num = page.text.strip()\n",
    "        try:\n",
    "            clean_page_num = int(clean_page_num)\n",
    "            if clean_page_num > max_page:\n",
    "                max_page = clean_page_num\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    list_of_page_urls = [sf.clean_search_url(search_keyword)]\n",
    "\n",
    "    # create list of reciepe urls\n",
    "    if max_page >= 2:\n",
    "        for page_num in range(2, max_page + 1):\n",
    "            clean_url = sf.clean_search_url(search_keyword, page_num=page_num)\n",
    "            list_of_page_urls.append(clean_url)\n",
    "\n",
    "    return list_of_page_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_html_texts(list_of_page_urls):\n",
    "    # get html text for all page that come up in search of keyword\n",
    "    list_of_html = []\n",
    "\n",
    "    for url in list_of_page_urls:\n",
    "        html = sf.get_html(url)\n",
    "        list_of_html.append(html)\n",
    "\n",
    "    return list_of_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_recipe_info(list_of_html):\n",
    "    # create df of name, author and link to recipe\n",
    "    recipe_df = pd.DataFrame(columns=['name', 'author', 'ingredients', 'url'])\n",
    "\n",
    "    for html in list_of_html:\n",
    "            searches_html = html.find_all('section', class_='o-RecipeResult o-ResultCard')\n",
    "\n",
    "            for recipe in searches_html:\n",
    "                recipe_name = recipe.find('a', class_='').span.text\n",
    "                try:\n",
    "                    recipe_author = recipe.find('span', class_='m-Info__a-AssetInfo').text.lstrip('Courtesy of ')\n",
    "                except:\n",
    "                    recipe_author = 'Unknown Author'\n",
    "                recipe_url = f\"http://{recipe.find('a', class_='')['href'].lstrip('/')}\"\n",
    "                recipe_df = recipe_df.append({'name': recipe_name, 'author': recipe_author, 'url': recipe_url},\n",
    "                                             ignore_index=True)\n",
    "\n",
    "    return recipe_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_recipe_ingredients(recipe_df):\n",
    "    for recipe_url in recipe_df.url:\n",
    "        try:\n",
    "            recipe_ingredients = sf.get_ingredients_from_url(recipe_url)\n",
    "        except:\n",
    "            recipe_ingredients = None\n",
    "\n",
    "        url_index = recipe_df.url[recipe_df.url == recipe_url].index[0]\n",
    "        recipe_df.at[url_index, 'ingredients'] = recipe_ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_df(recipe_df):\n",
    "    main_ingredients_series = pd.Series(dtype=str)\n",
    "\n",
    "    for ingredients_list in recipe_df['ingredients']:\n",
    "        if ingredients_list is not None:\n",
    "            ingredients_series = pd.Series(ingredients_list)\n",
    "            main_ingredients_series = main_ingredients_series.append(ingredients_series, ignore_index=True)\n",
    "\n",
    "    # todo make percentage and make another tab to put this in\n",
    "    freq_table = main_ingredients_series.value_counts()\n",
    "\n",
    "    return freq_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "all-purpose flour                                 13\nolive oil                                         11\negg                                               11\nkosher salt                                       10\ncloves garlic                                     10\n                                                  ..\nvegetable shortening                               1\nadobo sauce                                        1\nchopped cilantro leaves                            1\nleftover steak from the salisbury steak recipe     1\ncornstarch                                         1\nLength: 186, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ]
}